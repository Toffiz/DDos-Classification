{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46314514-93c6-4c96-8d23-13ec9597cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%py` not found.\n"
     ]
    }
   ],
   "source": [
    "%py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bb020a2-5f3b-4526-b247-ac587bb25979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DrDoS_DNS ===\n",
      "Уникальные IP в Source IP       : 120\n",
      "Уникальные IP в Destination IP : 113\n",
      "Уникальные IP всего            : 139\n",
      "Accuracy: 0.9669 | Precision: 0.8500 | Recall: 0.9444 | F1: 0.8947\n",
      "\n",
      "Mitigation Actions:\n",
      "172.16.0.5: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.10: RATE_LIMIT_10MBPS\n",
      "10.10.10.1: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.6: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "\n",
      "=== DrDoS_LDAP ===\n",
      "Уникальные IP в Source IP       : 30\n",
      "Уникальные IP в Destination IP : 9\n",
      "Уникальные IP всего            : 33\n",
      "Accuracy: 0.8065 | Precision: 0.8000 | Recall: 0.8889 | F1: 0.8421\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.8: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.14: RATE_LIMIT_10MBPS\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.1: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.6: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "\n",
      "=== DrDoS_MSSQL ===\n",
      "Уникальные IP в Source IP       : 68\n",
      "Уникальные IP в Destination IP : 53\n",
      "Уникальные IP всего            : 79\n",
      "Accuracy: 0.8824 | Precision: 0.7778 | Recall: 0.7778 | F1: 0.7778\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.1: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.6: RATE_LIMIT_10MBPS\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "\n",
      "=== DrDoS_NetBIOS ===\n",
      "Уникальные IP в Source IP       : 68\n",
      "Уникальные IP в Destination IP : 59\n",
      "Уникальные IP всего            : 84\n",
      "Accuracy: 0.9143 | Precision: 0.8000 | Recall: 0.8889 | F1: 0.8421\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.12: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "10.10.10.1: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.8: RATE_LIMIT_10MBPS\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "23.194.109.223: BLACKLIST\n",
      "\n",
      "=== DrDoS_NTP ===\n",
      "Уникальные IP в Source IP       : 340\n",
      "Уникальные IP в Destination IP : 355\n",
      "Уникальные IP всего            : 384\n",
      "Accuracy: 0.9849 | Precision: 0.7826 | Recall: 1.0000 | F1: 0.8780\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.5: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.6: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.1: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "172.217.12.138: RATE_LIMIT_10MBPS\n",
      "172.217.6.234: RATE_LIMIT_10MBPS\n",
      "224.0.0.251: BLACKLIST\n",
      "\n",
      "=== DrDoS_SNMP ===\n",
      "Уникальные IP в Source IP       : 36\n",
      "Уникальные IP в Destination IP : 17\n",
      "Уникальные IP всего            : 41\n",
      "Accuracy: 0.8286 | Precision: 0.8333 | Recall: 0.8333 | F1: 0.8333\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.18: RATE_LIMIT_10MBPS\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.1: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.6: RATE_LIMIT_10MBPS\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "\n",
      "=== DrDoS_SSDP ===\n",
      "Уникальные IP в Source IP       : 38\n",
      "Уникальные IP в Destination IP : 18\n",
      "Уникальные IP всего            : 45\n",
      "Accuracy: 0.8293 | Precision: 0.8235 | Recall: 0.7778 | F1: 0.8000\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.11: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "\n",
      "=== DrDoS_UDP ===\n",
      "Уникальные IP в Source IP       : 73\n",
      "Уникальные IP в Destination IP : 79\n",
      "Уникальные IP всего            : 105\n",
      "Accuracy: 0.9114 | Precision: 0.8667 | Recall: 0.7222 | F1: 0.7879\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.4: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.6: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.7: BLACKLIST\n",
      "10.10.10.12: RATE_LIMIT_10MBPS\n",
      "10.10.10.1: BLACKLIST\n",
      "10.10.10.19: RATE_LIMIT_10MBPS\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "\n",
      "=== Syn ===\n",
      "Уникальные IP в Source IP       : 27\n",
      "Уникальные IP в Destination IP : 11\n",
      "Уникальные IP всего            : 34\n",
      "Accuracy: 0.6400 | Precision: 0.8462 | Recall: 0.6111 | F1: 0.7097\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.8: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.10: RATE_LIMIT_10MBPS\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.6: RATE_LIMIT_10MBPS\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.17: RATE_LIMIT_10MBPS\n",
      "10.10.10.13: RATE_LIMIT_10MBPS\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.11: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "\n",
      "=== TFTP ===\n",
      "Уникальные IP в Source IP       : 29\n",
      "Уникальные IP в Destination IP : 11\n",
      "Уникальные IP всего            : 36\n",
      "Accuracy: 0.7333 | Precision: 0.8125 | Recall: 0.7222 | F1: 0.7647\n",
      "\n",
      "Mitigation Actions:\n",
      "172.16.0.5: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.6: BLACKLIST\n",
      "10.10.10.18: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.1: RATE_LIMIT_10MBPS\n",
      "10.10.10.10: RATE_LIMIT_10MBPS\n",
      "10.10.10.9: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.4: BLACKLIST\n",
      "10.10.10.12: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.20: RATE_LIMIT_10MBPS\n",
      "192.168.50.7: BLACKLIST\n",
      "23.32.166.121: RATE_LIMIT_10MBPS\n",
      "\n",
      "=== UDPLag ===\n",
      "Уникальные IP в Source IP       : 137\n",
      "Уникальные IP в Destination IP : 137\n",
      "Уникальные IP всего            : 163\n",
      "Accuracy: 0.9179 | Precision: 0.6842 | Recall: 0.7222 | F1: 0.7027\n",
      "\n",
      "Mitigation Actions:\n",
      "10.10.10.6: BLACKLIST\n",
      "192.168.50.1: BLACKLIST\n",
      "10.10.10.17: BLACKLIST\n",
      "10.10.10.4: RATE_LIMIT_10MBPS\n",
      "10.10.10.9: BLACKLIST\n",
      "172.16.0.5: BLACKLIST\n",
      "10.10.10.2: BLACKLIST\n",
      "10.10.10.10: BLACKLIST\n",
      "10.10.10.8: BLACKLIST\n",
      "10.10.10.15: BLACKLIST\n",
      "10.10.10.13: BLACKLIST\n",
      "10.10.10.3: BLACKLIST\n",
      "10.10.10.20: BLACKLIST\n",
      "10.10.10.16: BLACKLIST\n",
      "10.10.10.14: BLACKLIST\n",
      "10.10.10.5: BLACKLIST\n",
      "10.10.10.19: BLACKLIST\n",
      "10.10.10.1: BLACKLIST\n",
      "91.189.94.4: BLACKLIST\n",
      "224.0.0.251: BLACKLIST\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# -----------------------------\n",
    "# Загрузка и предварительная обработка данных для конкретного типа атаки\n",
    "# -----------------------------\n",
    "def load_attack_type(data_dir, attack_type, nrows=10000, n_attacks=20, amount_of_noise=0.3):\n",
    "    path = os.path.join(data_dir, f\"{attack_type}.csv\")\n",
    "    df = pd.read_csv(path, nrows=nrows, low_memory=False)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df['attack_type'] = attack_type\n",
    "    df['Label'] = df['Label'].map(lambda x: 0 if 'BENIGN' in str(x).upper() else 1)\n",
    "\n",
    "    # Разделяем на атакующие и нормальные строки\n",
    "    attack_df = df[df['Label'] == 1].copy()\n",
    "    benign_df = df[df['Label'] == 0].copy()\n",
    "\n",
    "    if not attack_df.empty:\n",
    "        generated_rows = []\n",
    "        for i in range(1, n_attacks + 1):\n",
    "            fake_ip = f\"10.10.10.{i}\"\n",
    "            new_rows = attack_df.sample(frac=0.3, replace=True, random_state=i).copy()\n",
    "            new_rows['Source IP'] = fake_ip\n",
    "\n",
    "            # Добавление шума в числовые признаки\n",
    "            num_cols = new_rows.select_dtypes(include=[np.number]).columns.difference(['Label'])\n",
    "            for col in num_cols:\n",
    "                std_dev = new_rows[col].std()\n",
    "                noise = np.random.normal(0, amount_of_noise * std_dev if not np.isnan(std_dev) and std_dev > 0 else 1, size=new_rows.shape[0])\n",
    "                new_rows[col] += noise\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                new_rows['Label'] = 0\n",
    "\n",
    "            generated_rows.append(new_rows)\n",
    "\n",
    "        attack_df = pd.concat([attack_df] + generated_rows, ignore_index=True)\n",
    "\n",
    "    df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    return df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Удаление строк с отсутствующими критическими значениями\n",
    "def preprocess_for_graph(df):\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# Построение графа на основе сетевых потоков\n",
    "# -----------------------------\n",
    "def build_graph(flow_df):\n",
    "    flow_df = flow_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # Создаем отображения IP в уникальные индексы узлов\n",
    "    ip_set = pd.unique(flow_df[['Source IP', 'Destination IP']].values.ravel())\n",
    "    ip_map = {ip: idx for idx, ip in enumerate(ip_set)}\n",
    "    reverse_ip_map = {idx: ip for ip, idx in ip_map.items()}\n",
    "\n",
    "    flow_df['src'] = flow_df['Source IP'].map(ip_map)\n",
    "    flow_df['dst'] = flow_df['Destination IP'].map(ip_map)\n",
    "\n",
    "    # Получаем числовые признаки для построения векторов узлов\n",
    "    numeric_cols = flow_df.select_dtypes(include=[np.number]).columns.difference(['src', 'dst', 'Label'])\n",
    "    node_features = []\n",
    "    for node in range(len(ip_set)):\n",
    "        rows = flow_df[flow_df['src'] == node]\n",
    "        features = rows[numeric_cols].mean().values if not rows.empty else np.zeros(len(numeric_cols))\n",
    "        node_features.append(features)\n",
    "\n",
    "    # Собираем DataFrame с признаками узлов\n",
    "    node_df = pd.DataFrame(node_features, columns=numeric_cols).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # Графовые тензоры\n",
    "    edge_index = torch.tensor(flow_df[['src', 'dst']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(StandardScaler().fit_transform(flow_df['Flow Bytes/s'].values.reshape(-1, 1)), dtype=torch.float)\n",
    "    x = torch.tensor(StandardScaler().fit_transform(node_df), dtype=torch.float)\n",
    "\n",
    "    # Выделяем атакующие узлы по IP\n",
    "    attack_nodes = np.union1d(flow_df[flow_df['Label'] == 1]['src'].unique(), flow_df[flow_df['Label'] == 1]['dst'].unique())\n",
    "    y = torch.tensor([1 if i in attack_nodes else 0 for i in node_df.index], dtype=torch.float)\n",
    "\n",
    "    # Сохраняем имена признаков узлов для анализа важности признаков\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    data.node_ip_map = reverse_ip_map\n",
    "    data.raw_flows = flow_df\n",
    "    data.feature_names = list(numeric_cols)  # <--- добавили сюда имена признаков\n",
    "    data.time_series = flow_df[['Timestamp', 'Flow Bytes/s']] if 'Timestamp' in flow_df.columns else None\n",
    "    return data\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Модель на основе сверточной графовой нейросети (GCN)\n",
    "# -----------------------------\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()\n",
    "\n",
    "\n",
    "# Обучение модели GCN\n",
    "def train(data, epochs, hidden_channels=32):\n",
    "    model = GCN(data.x.shape[1], hidden_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Оценка модели\n",
    "# -----------------------------\n",
    "def evaluate_model(model, data, threshold = 0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_scores = model(data).numpy()\n",
    "        y_true = data.y.numpy()\n",
    "        y_pred = (y_scores > threshold).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "    return y_true, y_scores, y_pred, acc, prec, rec, f1\n",
    "\n",
    "# Построение графиков метрик и матрицы ошибок\n",
    "def plot_feature_importance(model, data, pdf):\n",
    "    model.eval()\n",
    "    x = data.x.clone().detach().requires_grad_(True)  # включаем градиенты по входу\n",
    "    with torch.enable_grad():\n",
    "        output = model.forward(Data(x=x, edge_index=data.edge_index))\n",
    "        output.mean().backward()\n",
    "\n",
    "    grads = x.grad.abs().mean(dim=0).numpy()\n",
    "    names = data.feature_names\n",
    "\n",
    "    # Отбираем топ-10 признаков\n",
    "    importance = list(zip(names, grads))\n",
    "    importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_features = importance[:10]\n",
    "    top_names, top_grads = zip(*top_features)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(top_names[::-1], top_grads[::-1])  # отобразим от наибольшего сверху\n",
    "    plt.title(\"Top 10 Feature Importances (Gradient-based)\")\n",
    "    plt.xlabel(\"Average Gradient Magnitude\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(); plt.close()\n",
    "# ------------------------------\n",
    "# График изменения объема трафика во времени\n",
    "# -----------------------------\n",
    "def show_time_series(data, pdf):\n",
    "    if data.time_series is not None:\n",
    "        df = data.time_series.copy()\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "        df = df.dropna().sort_values('Timestamp')\n",
    "        df.set_index('Timestamp')['Flow Bytes/s'].plot(figsize=(10, 4), title=\"DDoS Behavior Over Time\")\n",
    "        plt.ylabel(\"Flow Bytes/s\")\n",
    "        plt.grid()\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Отображение топологии графа и выделение подозрительных узлов\n",
    "# -----------------------------\n",
    "def show_graph_topology(data, pdf, scores=None, threshold=0.5, title=\"Graph Topology\"):\n",
    "    G = nx.Graph()\n",
    "    flows = data.raw_flows\n",
    "    edges = list(zip(flows['src'], flows['dst']))\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    if scores is not None:\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            idx = node\n",
    "            score = scores[idx] if idx < len(scores) else 0\n",
    "            if score > threshold:\n",
    "                color_map.append('red')      # высокая вероятность атаки\n",
    "            elif score > 0.3:\n",
    "                color_map.append('orange')   # подозрительный\n",
    "            else:\n",
    "                color_map.append('green')    # нормальный\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color=color_map, with_labels=True, font_size=6, node_size=100)\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color='skyblue', with_labels=True, font_size=6, node_size=100)\n",
    "    plt.title(title)\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Стратегии смягчения последствий DDoS-атак\n",
    "# -----------------------------\n",
    "def get_mitigation_actions(data, scores, threshold_blacklist=0.5, threshold_limit=(0.3, 0.5)):\n",
    "    actions = []\n",
    "    for node_id, score in enumerate(scores):\n",
    "        ip = data.node_ip_map.get(node_id, f'Node{node_id}')\n",
    "        if score > threshold_blacklist:\n",
    "            actions.append((ip, 'BLACKLIST'))  # заблокировать IP\n",
    "        elif threshold_limit[0] <= score <= threshold_limit[1]:\n",
    "            actions.append((ip, 'RATE_LIMIT_10MBPS'))  # ограничить пропускную способность\n",
    "        elif score > 0.8:\n",
    "            actions.append((ip, 'SINKHOLE'))  # перенаправить в пустоту\n",
    "    return actions\n",
    "\n",
    "def check_unique_ips(df):\n",
    "    source_ips = df['Source IP'].unique()\n",
    "    destination_ips = df['Destination IP'].unique()\n",
    "    all_ips = pd.unique(df[['Source IP', 'Destination IP']].values.ravel())\n",
    "\n",
    "    print(f\"Уникальные IP в Source IP       : {len(source_ips)}\")\n",
    "    print(f\"Уникальные IP в Destination IP : {len(destination_ips)}\")\n",
    "    print(f\"Уникальные IP всего            : {len(all_ips)}\")\n",
    "    return all_ips\n",
    "\n",
    "def plot_feature_importance(model, data, pdf):\n",
    "    model.eval()\n",
    "    x = data.x.clone().detach().requires_grad_(True)  # включаем градиенты по входу\n",
    "    with torch.enable_grad():\n",
    "        output = model.forward(Data(x=x, edge_index=data.edge_index))\n",
    "        output.mean().backward()\n",
    "\n",
    "    grads = x.grad.abs().mean(dim=0).numpy()\n",
    "    names = data.feature_names\n",
    "\n",
    "    # Отбираем топ-10 признаков\n",
    "    importance = list(zip(names, grads))\n",
    "    importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_features = importance[:10]\n",
    "    top_names, top_grads = zip(*top_features)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(top_names[::-1], top_grads[::-1])  # отобразим от наибольшего сверху\n",
    "    plt.title(\"Top 10 Feature Importances (Gradient-based)\")\n",
    "    plt.xlabel(\"Average Gradient Magnitude\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "def inject_label_noise(df, flip_fraction=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    attack_indices = df[df['Label'] == 1].index\n",
    "    n_flip = int(len(attack_indices) * flip_fraction)\n",
    "    flip_indices = np.random.choice(attack_indices, n_flip, replace=False)\n",
    "    df.loc[flip_indices, 'Label'] = 0\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# Основной цикл: обучение и сохранение отчета для каждого типа атаки\n",
    "# -----------------------------\n",
    "data_dir = \"01-12\"\n",
    "all_attacks = [\n",
    "    \"DrDoS_DNS\", \"DrDoS_LDAP\", \"DrDoS_MSSQL\", \"DrDoS_NetBIOS\",\n",
    "    \"DrDoS_NTP\", \"DrDoS_SNMP\", \"DrDoS_SSDP\", \"DrDoS_UDP\",\n",
    "    \"Syn\", \"TFTP\", \"UDPLag\"\n",
    "]\n",
    "\n",
    "with PdfPages(\"ddos_gnn_report.pdf\") as pdf:\n",
    "    for attack_type in all_attacks:\n",
    "        print(f\"\\n=== {attack_type} ===\")\n",
    "        df = load_attack_type(data_dir, attack_type, nrows=100000, n_attacks=20, amount_of_noise=0.3)\n",
    "        check_unique_ips(df)\n",
    "        df = preprocess_for_graph(df)\n",
    "\n",
    "        df = inject_label_noise(df, flip_fraction=0.1)\n",
    "        \n",
    "        # Разделяем данные до построения графа\n",
    "        train_flows, test_flows = train_test_split(df, test_size=0.3, stratify=df['Label'], random_state=42)\n",
    "\n",
    "        # Строим графы\n",
    "        train_data = build_graph(train_flows)\n",
    "        test_data = build_graph(test_flows)\n",
    "\n",
    "        # Визуализация до атаки\n",
    "        show_graph_topology(train_data, pdf, title=f\"{attack_type}: Pre-Attack Topology\")\n",
    "        show_time_series(train_data, pdf)\n",
    "\n",
    "        # Обучение и тестирование\n",
    "        model = train(train_data, epochs=50, hidden_channels=32)\n",
    "        y_true, y_scores, y_pred, acc, prec, rec, f1 = evaluate_model(model, test_data, threshold=0.5)\n",
    "        plot_results(y_true, y_scores, y_pred, pdf)\n",
    "\n",
    "        plot_feature_importance(model, train_data, pdf)\n",
    "\n",
    "        # Визуализация после атаки\n",
    "        show_graph_topology(test_data, pdf, scores=y_scores, title=f\"{attack_type}: Post-Attack Topology\")\n",
    "\n",
    "        # Страница с итоговыми метриками\n",
    "        plt.figure()\n",
    "        plt.axis(\"off\")\n",
    "        text = f\"\"\"\n",
    "        Attack Type: {attack_type}\n",
    "\n",
    "        Accuracy : {acc:.4f}\n",
    "        Precision: {prec:.4f}\n",
    "        Recall   : {rec:.4f}\n",
    "        F1 Score : {f1:.4f}\n",
    "        \"\"\"\n",
    "        plt.text(0, 0.5, text, fontsize=12, fontfamily=\"monospace\")\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "        # Митигирующие действия\n",
    "        actions = get_mitigation_actions(test_data, y_scores)\n",
    "        print(\"\\nMitigation Actions:\")\n",
    "        for ip, action in actions:\n",
    "            print(f\"{ip}: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facb5012-6e86-47c4-9421-16e7bc6d35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4b978-da47-49f1-8b20-0aa467097ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DrDoS_DNS\n",
      "\n",
      "unique ips in source ip       : 152\n",
      "unique ips in dest ip         : 113\n",
      "total unique ips              : 169\n",
      "tp: 38, fp: 11, tn: 97, fn: 4\n",
      "accuracy: 0.9000, precision: 0.7755, recall: 0.9048, f1: 0.8352\n",
      "tpr: 0.9048, fpr: 0.1019\n",
      "\n",
      "mitigation actions:\n",
      "10.10.10.23: rate limit 10mbps\n",
      "192.168.50.1: blacklist\n",
      "10.10.10.41: blacklist\n",
      "10.10.10.11: blacklist\n",
      "10.10.10.17: blacklist\n",
      "10.10.10.39: blacklist\n",
      "172.16.0.5: blacklist\n",
      "10.10.10.9: blacklist\n",
      "10.10.10.15: blacklist\n",
      "10.10.10.42: blacklist\n",
      "10.10.10.28: blacklist\n",
      "10.10.10.7: blacklist\n",
      "10.10.10.8: blacklist\n",
      "10.10.10.1: blacklist\n",
      "10.10.10.19: blacklist\n",
      "10.10.10.24: blacklist\n",
      "10.10.10.16: blacklist\n",
      "10.10.10.3: blacklist\n",
      "10.10.10.38: blacklist\n",
      "10.10.10.6: blacklist\n",
      "10.10.10.18: blacklist\n",
      "10.10.10.31: blacklist\n",
      "10.10.10.45: blacklist\n",
      "10.10.10.46: blacklist\n",
      "10.10.10.37: blacklist\n",
      "10.10.10.27: rate limit 10mbps\n",
      "10.10.10.36: blacklist\n",
      "10.10.10.14: blacklist\n",
      "10.10.10.2: blacklist\n",
      "10.10.10.4: blacklist\n",
      "10.10.10.44: blacklist\n",
      "10.10.10.12: blacklist\n",
      "10.10.10.33: blacklist\n",
      "10.10.10.34: blacklist\n",
      "10.10.10.48: blacklist\n",
      "10.10.10.22: blacklist\n",
      "10.10.10.29: blacklist\n",
      "10.10.10.49: blacklist\n",
      "10.10.10.35: blacklist\n",
      "10.10.10.50: blacklist\n",
      "10.10.10.5: blacklist\n",
      "10.10.10.13: blacklist\n",
      "10.10.10.10: blacklist\n",
      "10.10.10.32: blacklist\n",
      "10.10.10.40: blacklist\n",
      "10.10.10.43: blacklist\n",
      "10.10.10.47: blacklist\n",
      "10.10.10.25: blacklist\n",
      "10.10.10.20: blacklist\n",
      "10.10.10.30: blacklist\n",
      "172.217.10.10: blacklist\n",
      "91.189.94.4: rate limit 10mbps\n",
      "\n",
      "DrDoS_LDAP\n",
      "\n",
      "unique ips in source ip       : 60\n",
      "unique ips in dest ip         : 12\n",
      "total unique ips              : 66\n"
     ]
    }
   ],
   "source": [
    "#first we import all the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "#proving brownish/beige palette for non topology plots in order to match with our paper colours\n",
    "PALETTE = {\n",
    "    'dark':   '#8b4513',  \n",
    "    'med':    '#deb887',  \n",
    "    'light':  '#f5deb3',  \n",
    "    'accent': '#cd853f'   \n",
    "}\n",
    "\n",
    "#label encoding\n",
    "def load_attack_type(data_dir, attack_type, nrows=10000, n_attacks=20, amount_of_noise=0.3):\n",
    "    path = os.path.join(data_dir, f\"{attack_type}.csv\")\n",
    "    df = pd.read_csv(path, nrows=nrows, low_memory=False)\n",
    "    df.columns = df.columns.str.strip()  #removing extra spaces in headers\n",
    "    df['attack_type'] = attack_type      \n",
    "    df['Label'] = df['Label'].map(lambda x: 0 if 'benign' in str(x).lower() else 1)\n",
    "\n",
    "    attack_df = df[df['Label'] == 1].copy()  #attack flows\n",
    "    benign_df = df[df['Label'] == 0].copy()  #benign flows\n",
    "\n",
    "    if not attack_df.empty:\n",
    "        generated = []\n",
    "        for i in range(1, n_attacks + 1):\n",
    "            fake_ip = f\"10.10.10.{i}\"\n",
    "            rows = attack_df.sample(frac=0.3, replace=True, random_state=i).copy()\n",
    "            rows['Source IP'] = fake_ip\n",
    "\n",
    "            #gaussian noise to numeric features \n",
    "            num_cols = rows.select_dtypes(include=[np.number]).columns.difference(['Label'])\n",
    "            for col in num_cols:\n",
    "                vals = rows[col].dropna()\n",
    "                std_dev = vals.std(ddof=0) if len(vals) > 0 else 0\n",
    "                sigma = amount_of_noise * std_dev if std_dev > 0 else 1\n",
    "                rows[col] += np.random.normal(0, sigma, size=rows.shape[0])\n",
    "\n",
    "            #flipping some labels back to benign\n",
    "            if i % 5 == 0:\n",
    "                rows['Label'] = 0\n",
    "\n",
    "            generated.append(rows)\n",
    "\n",
    "        attack_df = pd.concat([attack_df] + generated, ignore_index=True)\n",
    "\n",
    "    df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    return df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#placeholder for any df cleaning steps\n",
    "def preprocess_for_graph(df):\n",
    "    return df\n",
    "\n",
    "#convertinh flow dataframe into a torch_geometric data object\n",
    "def build_graph(flow_df):\n",
    "    #replacing inf and nans with 0s\n",
    "    flow_df = flow_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    #mapping each ip to a unique node index\n",
    "    ip_set = pd.unique(flow_df[['Source IP', 'Destination IP']].values.ravel())\n",
    "    ip_map = {ip: idx for idx, ip in enumerate(ip_set)}\n",
    "    rev_map = {idx: ip for ip, idx in ip_map.items()}\n",
    "\n",
    "    flow_df['src'] = flow_df['Source IP'].map(ip_map)\n",
    "    flow_df['dst'] = flow_df['Destination IP'].map(ip_map)\n",
    "\n",
    "    #building node feature matrix by avg numeric cols per node\n",
    "    num_cols = flow_df.select_dtypes(include=[np.number]).columns.difference(['src', 'dst', 'Label'])\n",
    "    node_features = []\n",
    "    for node in range(len(ip_set)):\n",
    "        sub = flow_df[flow_df['src'] == node]\n",
    "        feat = sub[num_cols].mean().values if not sub.empty else np.zeros(len(num_cols))\n",
    "        node_features.append(feat)\n",
    "    node_df = pd.DataFrame(node_features, columns=num_cols).fillna(0)\n",
    "\n",
    "    #edge_index/edge_attr tensors\n",
    "    edge_index = torch.tensor(flow_df[['src', 'dst']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(\n",
    "        StandardScaler().fit_transform(flow_df['Flow Bytes/s'].values.reshape(-1, 1)),\n",
    "        dtype=torch.float\n",
    "    )\n",
    "    x = torch.tensor(StandardScaler().fit_transform(node_df), dtype=torch.float)\n",
    "\n",
    "    #labeling nodes as attack if any incident flow has Label=1\n",
    "    attack_nodes = np.union1d(\n",
    "        flow_df[flow_df['Label'] == 1]['src'].unique(),\n",
    "        flow_df[flow_df['Label'] == 1]['dst'].unique()\n",
    "    )\n",
    "    y = torch.tensor([1 if i in attack_nodes else 0 for i in range(len(node_df))], dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    data.node_ip_map = rev_map             #mapping back to IP\n",
    "    data.raw_flows = flow_df               #keeping raw flow df for plotting\n",
    "    data.feature_names = list(num_cols)    #we save feature names for importance\n",
    "    data.time_series = flow_df[['Timestamp', 'Flow Bytes/s']] \\\n",
    "        if 'Timestamp' in flow_df.columns else None\n",
    "    return data\n",
    "\n",
    "#defining gnn model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()\n",
    "\n",
    "#training\n",
    "def train(data, epochs, hidden_channels=32):\n",
    "    model = GCN(data.x.shape[1], hidden_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "#metrics evaluation\n",
    "def evaluate_model(model, data, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(data).numpy()\n",
    "        true = data.y.numpy()\n",
    "        pred = (scores > threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(true, pred)\n",
    "    prec = precision_score(true, pred, zero_division=0)\n",
    "    rec = recall_score(true, pred, zero_division=0)\n",
    "    f1 = f1_score(true, pred, zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    print(f\"tp: {tp}, fp: {fp}, tn: {tn}, fn: {fn}\")\n",
    "    print(f\"accuracy: {acc:.4f}, precision: {prec:.4f}, recall: {rec:.4f}, f1: {f1:.4f}\")\n",
    "    print(f\"tpr: {tpr:.4f}, fpr: {fpr:.4f}\")\n",
    "\n",
    "    return true, scores, pred, acc, prec, rec, f1, tp, fp, tn, fn\n",
    "\n",
    "#plot feature importances \n",
    "def plot_feature_importance(model, data, pdf):\n",
    "    model.eval()\n",
    "    x = data.x.clone().detach().requires_grad_(True)\n",
    "    with torch.enable_grad():\n",
    "        out = model(Data(x=x, edge_index=data.edge_index))\n",
    "        out.mean().backward()\n",
    "    grads = x.grad.abs().mean(dim=0).numpy()\n",
    "    names = data.feature_names\n",
    "    imp = sorted(zip(names, grads), key=lambda z: z[1], reverse=True)[:10]\n",
    "    top_names, top_grads = zip(*imp)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(top_names[::-1], top_grads[::-1], color=PALETTE['med'])\n",
    "    plt.title(\"top10 feature importances\")\n",
    "    plt.xlabel(\"avg gradient magnitude\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#roc and precision recall curves\n",
    "def plot_roc_pr(y_true, y_scores, pdf):\n",
    "    fpr_vals, tpr_vals, _ = roc_curve(y_true, y_scores)\n",
    "    auc_val = auc(fpr_vals, tpr_vals)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_vals, tpr_vals, color=PALETTE['dark'], label=f\"auc={auc_val:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=PALETTE['light'])\n",
    "    plt.xlabel(\"fpr\"); plt.ylabel(\"tpr\"); plt.title(\"roc curve\"); plt.legend()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_true, y_scores)\n",
    "    plt.figure()\n",
    "    plt.plot(rec_vals, prec_vals, color=PALETTE['accent'])\n",
    "    plt.xlabel(\"recall\"); plt.ylabel(\"precision\"); plt.title(\"precision recall curve\")\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#showing how tpr/fpr/precision vary with threshold\n",
    "def plot_threshold_metrics(y_true, y_scores, pdf):\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tprs, fprs, precs = [], [], []\n",
    "    for t in thresholds:\n",
    "        p = (y_scores >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, p).ravel()\n",
    "        tprs.append(tp / (tp + fn) if tp + fn > 0 else 0)\n",
    "        fprs.append(fp / (fp + tn) if fp + tn > 0 else 0)\n",
    "        precs.append(precision_score(y_true, p, zero_division=0))\n",
    "    plt.figure()\n",
    "    plt.plot(thresholds, tprs, label=\"tpr\", color=PALETTE['dark'])\n",
    "    plt.plot(thresholds, fprs, label=\"fpr\", color=PALETTE['med'])\n",
    "    plt.plot(thresholds, precs, label=\"precision\", color=PALETTE['accent'])\n",
    "    plt.xlabel(\"threshold\"); plt.ylabel(\"rate\"); plt.title(\"threshold vs metrics\"); plt.legend()\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#heatmap\n",
    "def plot_confusion_heatmap(y_true, y_pred, pdf):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cmap = sns.light_palette(PALETTE['dark'], as_cmap=True)\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap,\n",
    "                xticklabels=[\"benign\", \"attack\"],\n",
    "                yticklabels=[\"benign\", \"attack\"])\n",
    "    plt.title(\"confusion matrix\"); plt.xlabel(\"predicted\"); plt.ylabel(\"actual\")\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#plot flow bytes/s over time\n",
    "def show_time_series(data, pdf):\n",
    "    if data.time_series is not None:\n",
    "        df = data.time_series.copy()\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "        df = df.dropna().sort_values('Timestamp')\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(df['Timestamp'], df['Flow Bytes/s'], color=PALETTE['accent'])\n",
    "        plt.title(\"ddos behavior over time\"); plt.ylabel(\"flow bytes/s\"); plt.grid()\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "#drawing the netraph n highlighting suspicious nodes\n",
    "def show_graph_topology(data, pdf, scores=None, threshold=0.5, title=\"graph topology\"):\n",
    "    G = nx.Graph()\n",
    "    flows = data.raw_flows\n",
    "    G.add_edges_from(zip(flows['src'], flows['dst']))\n",
    "\n",
    "    if scores is not None:\n",
    "        color_map = []\n",
    "        for node in G:\n",
    "            s = scores[node] if node < len(scores) else 0\n",
    "            if s > threshold:\n",
    "                color_map.append('red')\n",
    "            elif s > 0.3:\n",
    "                color_map.append('orange')\n",
    "            else:\n",
    "                color_map.append('green')\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color=color_map, with_labels=True, font_size=6, node_size=100)\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        nx.draw(G, node_color='brown', with_labels=True, font_size=6, node_size=100)\n",
    "\n",
    "    plt.title(title)\n",
    "    pdf.savefig(); plt.close()\n",
    "\n",
    "#getting mitigation actions where we decide to block/limit/sinkhole based on scores obtained\n",
    "def get_mitigation_actions(data, scores, threshold_blacklist=0.5, threshold_limit=(0.3, 0.5)):\n",
    "    actions = []\n",
    "    for nid, sc in enumerate(scores):\n",
    "        ip = data.node_ip_map.get(nid, f'node{nid}')\n",
    "        if sc > threshold_blacklist:\n",
    "            actions.append((ip, 'blacklist'))\n",
    "        elif threshold_limit[0] <= sc <= threshold_limit[1]:\n",
    "            actions.append((ip, 'rate limit 10mbps'))\n",
    "        elif sc > 0.8:\n",
    "            actions.append((ip, 'sinkhole'))\n",
    "    return actions\n",
    "\n",
    "#printing counts of unique source/dest IPs\n",
    "def check_unique_ips(df):\n",
    "    s = len(df['Source IP'].unique())\n",
    "    d = len(df['Destination IP'].unique())\n",
    "    a = len(pd.unique(df[['Source IP', 'Destination IP']].values.ravel()))\n",
    "    print(f\"unique ips in source ip       : {s}\")\n",
    "    print(f\"unique ips in dest ip         : {d}\")\n",
    "    print(f\"total unique ips              : {a}\")\n",
    "    return a\n",
    "\n",
    "#inject label noise method \n",
    "\n",
    "def inject_label_noise(df, flip_fraction=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    idxs = df[df['Label'] == 1].index\n",
    "    n_flip = int(len(idxs) * flip_fraction)\n",
    "    flips = np.random.choice(idxs, n_flip, replace=False)\n",
    "    df.loc[flips, 'Label'] = 0\n",
    "    return df\n",
    "    \n",
    "#datapath to file, one of the main parts \n",
    "\n",
    "data_dir = \"01-12\"\n",
    "all_attacks = [\n",
    "    \"DrDoS_DNS\", \"DrDoS_LDAP\", \"DrDoS_MSSQL\", \"DrDoS_NetBIOS\",\n",
    "    \"DrDoS_NTP\", \"DrDoS_SNMP\", \"DrDoS_SSDP\", \"DrDoS_UDP\",\n",
    "    \"Syn\", \"TFTP\", \"UDPLag\"\n",
    "]\n",
    "\n",
    "with PdfPages(\"visualizationrep.pdf\") as pdf:\n",
    "    for atk in all_attacks:\n",
    "        print(f\"\\n{atk}\\n\")\n",
    "        df = load_attack_type(data_dir, atk, nrows=200000, n_attacks=50, amount_of_noise=0.15)\n",
    "        check_unique_ips(df)\n",
    "        df = preprocess_for_graph(df)\n",
    "        df = inject_label_noise(df, flip_fraction=0.05)\n",
    "\n",
    "        #spliting into train/test flows\n",
    "        train_flows, test_flows = train_test_split(\n",
    "            df, test_size=0.3, stratify=df['Label'], random_state=42\n",
    "        )\n",
    "\n",
    "        train_data = build_graph(train_flows)\n",
    "        test_data = build_graph(test_flows)\n",
    "\n",
    "        #visualization before attack pre\n",
    "        show_graph_topology(train_data, pdf, title=f\"{atk}: pre atk topology\")\n",
    "        show_time_series(train_data, pdf)\n",
    "\n",
    "        #training and evaluating\n",
    "        model = train(train_data, epochs=50, hidden_channels=32)\n",
    "        y_true, y_scores, y_pred, acc, prec, rec, f1, tp, fp, tn, fn = evaluate_model(\n",
    "            model, test_data\n",
    "        )\n",
    "\n",
    "        #some performance plots\n",
    "        plot_roc_pr(y_true, y_scores, pdf)\n",
    "        plot_threshold_metrics(y_true, y_scores, pdf)\n",
    "        plot_confusion_heatmap(y_true, y_pred, pdf)\n",
    "        plot_feature_importance(model, train_data, pdf)\n",
    "\n",
    "        #post attck visualization\n",
    "        show_graph_topology(test_data, pdf, scores=y_scores, title=f\"{atk}: post atk topology\")\n",
    "\n",
    "        #summary\n",
    "        plt.figure()\n",
    "        plt.axis('off')\n",
    "        summary = (\n",
    "            f\"attack: {atk}\\n\\n\"\n",
    "            f\"accuracy: {acc:.4f}  precision: {prec:.4f}\\n\"\n",
    "            f\"recall: {rec:.4f}  f1: {f1:.4f}\\n\"\n",
    "            f\"tp: {tp}  fp: {fp}  tn: {tn}  fn: {fn}\"\n",
    "        )\n",
    "        plt.text(0, 0.5, summary, fontsize=12, fontfamily=\"monospace\")\n",
    "        pdf.savefig(); plt.close()\n",
    "\n",
    "        #mitigation actions\n",
    "        actions = get_mitigation_actions(test_data, y_scores)\n",
    "        print(\"\\nmitigation actions:\")\n",
    "        for ip, act in actions:\n",
    "            print(f\"{ip}: {act}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d33db9-319e-4b4b-940e-93541d72c76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.2.2\n",
      "numpy version: 1.26.4\n",
      "torch version: 2.2.2+cpu\n",
      "scikit-learn version: 1.5.2\n",
      "matplotlib version: 3.9.2\n",
      "seaborn version: 0.13.2\n",
      "networkx version: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")\n",
    "print(f\"networkx version: {nx.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4baf7-6194-4c5e-a67e-3c1a447bf045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
